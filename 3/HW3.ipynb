{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c6d0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request as req\n",
    "import bs4\n",
    "# ssl問題，參考https://forums.raspberrypi.com/viewtopic.php?t=255167\n",
    "import ssl\n",
    "\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.set_ciphers('HIGH:!DH:!aNULL') \n",
    "\n",
    "file1 = open(\"ntnu_web.json\", mode=\"w\", encoding=\"utf-8\")  # 開啟一個文件\n",
    "file2 = open(\"ntnu_web.csv\", mode=\"w\", encoding=\"utf-8\")  # 再開啟一個文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df317a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義函式抓取網頁內容\n",
    "def getContent(url):\n",
    "    # 讓網頁覺得我們是正常瀏覽器，所以附加Request Headers(可省略)\n",
    "    request = req.Request(url, headers={\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/97.0.4692.99 Safari/537.36\"\n",
    "    })\n",
    "\n",
    "    with req.urlopen(request, context=ctx) as response:\n",
    "        data = response.read().decode(\"utf-8\")  # 中文編碼\n",
    "\n",
    "    # 解析原始碼，取的每篇文章的標題\n",
    "    search = bs4.BeautifulSoup(data, \"html.parser\")\n",
    "    contents = search.find_all(\"div\", class_=\"index-news-list\")  # 尋找class=\"index-news-list\"的div標籤\n",
    "    \n",
    "    # 定義一個list，並將每篇文章的href添加至其中\n",
    "    href_list = []\n",
    "    for tag in contents:\n",
    "        file1.write(tag.a.text + \"\\n\")  # 寫入資料\n",
    "        file2.write(tag.a.text + \"\\n\")  # 寫入資料\n",
    "        href_list.append(tag.a[\"href\"][:])\n",
    "    return href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aeb7fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義函式搜尋href_list所抓取href的網頁，並抓取所需資料\n",
    "def main(url):\n",
    "    request = req.Request(url)\n",
    "    with req.urlopen(request, context=ctx) as response:\n",
    "        data = response.read().decode(\"utf-8\")  # 中文編碼\n",
    "\n",
    "    # 解析原始碼，取的每篇文章的標題\n",
    "    search = bs4.BeautifulSoup(data, \"html.parser\")\n",
    "    news = search.find_all(\"div\", class_=\"news-content\")  # 尋找class=\"news-content\"的div標籤\n",
    "    \n",
    "    for tag in news:\n",
    "        lis1 = tag.find_all(\"h3\") # 抓取所有字號3的標題\n",
    "        for h3 in lis1:\n",
    "            file1.write(h3.text + \"\\n\")  # 寫入資料\n",
    "            file2.write(h3.text + \"\\n\")  # 寫入資料\n",
    "        lis2 = tag.find_all(\"p\") # 抓取所有<p>標籤內的文字\n",
    "        for p in lis2:\n",
    "            file1.write(p.text + \"\\n\")  # 寫入資料\n",
    "            file2.write(p.text + \"\\n\")  # 寫入資料\n",
    "        lis3 = tag.find_all(\"li\") # 抓取所有<li>標籤內的文字\n",
    "        for li in lis3:\n",
    "            file1.write(li.text + \"\\n\")  # 寫入資料\n",
    "            file2.write(li.text + \"\\n\")  # 寫入資料\n",
    "        lis4 = tag.find_all(\"div\") # 抓取所有<div>標籤內的文字\n",
    "        for div in lis4:\n",
    "            if div.text != \"回上一頁\": # 不寫入\"回上一頁\"\n",
    "                file1.write(div.text + \"\\n\")  # 寫入資料\n",
    "                file2.write(div.text + \"\\n\")  # 寫入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cb46304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程式\n",
    "pageURL = \"https://www.ntnu.edu.tw/\"\n",
    "file1.write(\"--------第1頁--------\" + \"\\n\")\n",
    "file2.write(\"--------第1頁--------\" + \"\\n\")\n",
    "href_list = getContent(pageURL)\n",
    "\n",
    "# 利用迴圈重複搜尋網頁\n",
    "count = 1\n",
    "# 校網僅有20個在class=\"news-content\"的div標籤內的文章，加上首頁共21頁\n",
    "# 數字設定超過21會出，程式可執行但21頁後無資料可抓取\n",
    "while count < 21:\n",
    "    # 首個數值在href_list[0]\n",
    "    nextURL = href_list[count-1]\n",
    "    # 寫入從第2頁\n",
    "    file1.write(\"--------第\" + str(count+1) + \"頁--------\" + \"\\n\")\n",
    "    file2.write(\"--------第\" + str(count+1) + \"頁--------\" + \"\\n\")\n",
    "    main(nextURL)\n",
    "    count += 1\n",
    "\n",
    "file1.close()  # 關閉文件\n",
    "file2.close()  # 關閉文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb24b5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
